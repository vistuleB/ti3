|> Sub
    title=Majority

    Unser ZiEl in diesem Teilkapitel ist es, Schaltkreise
    für die Majority-Funktion zu bauen:

    |> figure
        |> img
            style=height:10em
            src=./img/circuits/majority.svg
            loading=lazy

    Diese nimmt $n$ Bits als Input und gibt 1 aus, wenn mehr
    als $n/2$ davon 1 sind. Für $n=3$ heißt dass, das
    mindestens zwei Input-Bits 1 sein müssen. Als Formel kann
    man das so schreiben:

    $$
    \maj_3(x,y,z) = (x \wedge y) \vee (x \wedge z) \vee (y \wedge z)
    $$

    und als Schaltkreis so:

    |> figure
        |> img
            style=height:8em
            src=./img/circuits/maj3.svg
            loading=lazy

    Wie können wir das sinnvoll verallgemeinern für größere
    $n$? Was geschieht, wenn wir einfach die
    Wahrheitstabellen-Methode anwenden? Falls $n$ ungerade
    ist, dann sieht man leicht, dass die Wahrheitstabelle in
    genau $2^{n-1}$ vielen Zeilen eine 1 stehen hat und in
    ebenso vielen eine 0.

    |> Exercise
        Sei $n$ eine ungerade Zahl. Zeigen Sie, dass $\maj_n$
        für genau die Hälfte aller $2^n$ möglichen Eingaben
        eine 1 ausgibt (und für die andere Hälfte eine 0).

    Wir erhielten also eine DNF mit $2^{n-1}$ vielen
    AND-Gates. Das ist sehr groß, gemessen daran, dass Zählen
    und mit $n/2$ vergleichen ja nicht besonders schwierig
    klingt. Hier ist eine kleine Verbesserung, demonstriert
    am Beispiel $n=7$. Wenn wir für $n=7$ mit Hilfe einer
    Wahrheitstabelle eine DNF konstruieren, erhalten wir ja
    unter Anderem den Term

    $$
    T := x_1 \bar{x}_2 x_3 x_4 \bar{x}_5 x_6 x_7 \ ,
    $$

    da der Input $\maj_7(1011011) = 1$ ist. Schauen wir uns
    nun den Term $T'$ an, den wir erhalten, wenn wir alle
    negativen Literale aus $T$ löschen:

    $$
    T' := x_1 x_3 x_4 x_6 x_7 \ .
    $$

    Wenn dieser Term 1 wird, dann sind
    $x_1 = x_3 = x_4 = x_6 = x_7$ sein, also insgesamt fünf
    Input-Bits 1, und $\maj_7$ gibt 1 aus. Hier ist also
    eine Vereinfachung: wir folgen der
    Wahrheitstabellen-Methode, lassen aber alle negativen
    Literale weg. Das Ergebnis ist etwas kleiner und immer
    noch korrekt. Schauen Sie sich nun den Term

    $$
    x_1 \bar{x}_2 \bar{x}_3 x_4 \bar{x}_5 x_6 x_7
    $$

    an. Auch dieser kommt in der Wahrheitstabelle vor, da
    $\maj_7(1001011)=1$ gilt. In unserer neuen Konstruktion
    wird dieser zu $x_1 x_4 x_6 x_7$ vereinfacht. Nun
    schauen Sie: wenn $T'$ den Wert 1 ausgibt, dann gibt
    $x_1 x_4 x_6 x_7$ auf jeden Fall 1 aus, und $\maj_7$
    wird 1; $T'$ ist also redundant. Irgendwie ist das ja
    auch klar: zu verlangen, dass die fünf Variablen
    $x_1, x_3, x_4 x_6, x_7$ alle mit 1 abstimmen, ist zwar
    hinreichend, aber eben schon mehr als nötig. Es reicht
    also, sich auf alle Terme mit genau 4 Variablen zu
    beschränken. Im allgemeinen sei
    $k = \ceil{\frac{k+1}{2}}$. Dann gilt

    \begin{align}
    \maj_n (x_1,\dots,x_n) = \bigvee_{\substack{I \subseteq [n] \\ |I| = k}} \bigwedge_{i \in I} x_i
    .
    \label{johns-equation}
    \end{align}

    Diese Konstruktion hat nun ${n \choose k}$ Terme, von
    denen jeder aus $k$ Variablen besteht. Ist das nun gut
    oder schlecht?

    |> Statement
        title=*Lemma*
        Es gilt

        $$
        {n \choose {\ceil{n/2}}} \geq \frac{2^n}{n+1} \ .
        $$

    |> Highlight
        title=*Beweis.*
        Sei $k \in \{1,\dots,n\}$. Vergleichen wir
        ${n \choose k}$ mit ${n \choose k-1}$:

        \begin{align*}
        \frac{{n \choose k}}{{n \choose k-1}} & =
        \frac{ \frac{n!}{k! (n-k)!}}{\frac{n!}{ (k-1)! (n-k+1)!}} = \frac{n-k+1}{k}
        \end{align*}

        und somit

        \begin{align*}
        {n \choose k} & \geq {n \choose k-1} \quad \Longleftrightarrow \\
        n-k+1 & \geq k \quad \Longleftrightarrow \\
        2k & \leq n+1 \quad \Longleftrightarrow \\
        k & \leq \frac{n+1}{2} \quad \Longleftrightarrow \\
        k & \leq \floor{ \frac{n+1}{2}} = \ceil{\frac{n}{2}} \ .
        \end{align*}

        Aus der letzten Zeile folgt nun, dass ${n \choose k}$
        durch $k := \ceil{\frac{n}{2}}$ maximiert wird, also
        ${n \choose k} \leq {n \choose \ceil{\frac{n}{2}}}$
        gilt. Als nächstes müssen wir uns die Definition von
        ${n \choose k}$ ins Gedächtnis rufen. Nein,
        $\frac{n!}{k!(n-k)!}$ ist nicht die Definition,
        sondern eine Formel dafür. Die Definition ist:
        ${n \choose k}$ ist die Menge der Teilmengen von
        $\{1,\dots,n\}$, die Größe $k$ haben. Wieviele
        Teilmenge (jeglicher Größe) gibt es insgesamt? Genau
        $2^n$ viele: Sie müssen für jede Zahl
        $i \in \{1,\dots,n\}$ die Entscheidung treffen, ob $i$
        in die Menge soll oder nicht, haben also insgesamt
        $2^n$ Wahlmöglichkeiten. Daher gilt:

        $$
        \sum_{k=0}^n {n \choose k} = 2^n \ .
        $$

        Intuitiv gesprochen heißt das: diese Summe hat $n+1$
        Terme ( $k$ wandert von 0 bis $n$, also muss der
        größte Term mindestens ein $(n+1)$-tel des
        Gesamtbetrages sein. Formal:

        $$
        2^n = \sum_{k=0}^n {n \choose k} \leq \sum_{k=0}^n {n \choose \ceil{\frac{n}{2}}}
        = (n+1) \cdot {n \choose \ceil{\frac{n}{2}}}
        $$

        und somit

        $$
        {n \choose \ceil{\frac{n}{2}}} \geq \frac{2^n} {n+1} \ ,
        $$

        wie behauptet.
        |> QED

    Unsere neue, bessere Konstruktion benötigt also immer
    noch mindestens $\frac{2^n}{n+1}$ Terme, was bereits für
    moderate Werte wie $n=30$ nicht vertretbar ist.

    |> Topic
        Majority Top-Down mit `if-then-else`-Gates

    Wenden wir nun statt Wahrheitstabelle die
    Top-Down-Methode an, modifiziert für monotone Funktionen
    wie in den [Lösungen zu den
    Übungsaufgaben](>>monotone-circuits) dargestellt.
    Insbesondere definieren wir Verallgemeinerungen von
    $\maj_n$ wie folgt:

    \begin{align*}
    \theta^n_k (x_1,\dots,x_n) & :=
    \begin{cases}
    1 & \textnormal{ falls $x_1 + \dots + x_n \geq k$} \\
    0 & \textnormal{ sonst.}
    \end{cases}
    \end{align*}

    Die Funktion $\maj_n$ ist also ein Speziallfall
    $\theta^n_k$ für $k = \ceil{\frac{n+1}{2}}$. Wir können
    $\theta^n_k$ rekursiv zerlegen wie folgt:

    $$
    \theta^n_k (x_1,\dots,x_n) =
    (x_n \wedge \theta^{n-1}_{k-1} (x_1,\dots,x_{n-1}))
    \vee
    \theta^{n-1}_{k} (x_1,\dots,x_{n-1}) \
    $$

    und somit $\theta^n_k$ aus $\theta^{n-1}_{k-1}$ und
    $\theta^{n-1}_k$ berechnen. Rekursiv fortgefühtr sieht
    das dann so aus:

    |> figure
        |> img
            style=height:15em
            src=./img/circuits/majority-theta-recursive.svg
            loading=lazy

    Die Konstruktion endet mit $\theta^m_0$, was immer $1$
    ausgibt, und mit $\theta^m_{m}$, was
    $x_1 \wedge \dots \wedge x_m$ ist. Die Konstruktion ist
    leider auch nicht effizient; wenn man mit $C^n_k$ die
    Anzahl der $\theta^m_m$ und $\theta^m_0$ in diesem Baum
    zählt, dann sieht man, dass

    \begin{align*}
    C^n_k & = C^{n-1}_{k-1} + C^{n-1}_k \\
    C^n_n & = 1 \\
    C^n_0 & = 1
    \end{align*}

    gilt; sie erfüllt also die gleiche Rekursionsgleichung
    wie der Binomialkoeffizient ${n \choose k}$, also gilt
    $C^n_k = {n \choose k}$. Die Konstruktion ist
    asymptotisch auch nicht besser als die, aus der
    Wahrheitstabelle direkt eine monotone DNF zu basteln.
    Allerdings können wir die obige Konstruktion
    offensichtlich effizienter machen, indem wir mehrfach
    verwendete Zwischenergebnisse wie $\theta^{n-1}_{k-1}$
    nicht doppelt berechnen, also statt dem obigen Baum einen
    Schaltkreis nach folgendem Pyramidenschema bauen:

    |> figure
        |> img
            style=height:18em
            src=./img/circuits/majority-theta-dp.svg
            loading=lazy

    Um eine Analogie mit der Programmierpraxis zu bemühen:
    der Unterschied zwischen den beiden Konstruktionen für
    $\theta^n_k$ per Baum versus per Pyramidenschema
    entspricht dem Unterschied zwischen dem rekursiven Code
    für ${n \choose k}$,

    |> pre
        class=listing
        def binomial(n,k):
        \    if k == 0 or k == n:
        \        return 1
        \    else:
        \        return binomial(n-1,k-1) + binomial(n-1,k)

    der exponentielle Laufzeit aufweist, und der effizienten
    Implementierung mittels _Dynamic Programming_, bei
    welchem wir uns die Zwischenergebnisse merken. Um Größe
    und Tiefe des Schaltkreises zu analysieren, machen wir
    eine grobe Abschätzung. Für jedes $\theta^m_l$, das in
    unserer Pyramide vorkommt, brauchen wir 2 Gates; $m$
    kann die Werte $0, \dots, n$ annehmen und $l$ die Werte
    $0,\dots,k$, also bekommen wir insgesamt höchstens
    $(n+1)(k+1)$ graue Kästchen und $O(n^2)$ Gates. Die
    Tiefe ist $O(n)$, da in jedem Schritt von grauem Kasten
    zu dem nächsttieferen der Wert von $m$ abnimmt.
    Insgesamt also haben wir gezeigt:

    |> Statement
        title=*Theorem*
        Die Funktion $\maj_n (x_1,\dots,x_n)$ kann mit einem
        Schaltkreis der Größe $O(n^2)$, Tiefe $O(n)$ und
        Fan-in 2 berechnet werden.

    |> Topic
        Majority durch Zählen

    $\maj_n(x_1,\dots,x_n)$ zu bestimmen sollte doch einfach
    sein: wir zählen die Anzahl der 1en und vergleichen sie
    mit $\ceil{n}{2}$. Wie aber sollen wir zählen? Ganz
    einfach: mit einem Binäraddierer! Sei
    $d = \ceil{\log_2(n+1)}$ die Anzahl der Bits in der
    Binärdarstellung von $n$. Wir interpretieren jede
    Input-Variable $x_i$ als $d$-stellige Binärzahl, wobei
    $x_i = 1$ der Zahl $000\dots 001$, also 1 entspricht,
    und $x_i = 0$ der Zahl $000\dots 0$, also 0, und
    addieren die dann auf:

    |> figure
        |> img
            style=height:12em
            src=./img/circuits/majority-by-adding.svg
            loading=lazy

    |> Exercise
        Bestimmen Sie asymptotisch die Größe und die Tiefe
        dieses Schaltkreises. Achten Sie besonders bei der
        Berechnung der Größe darauf, dass die untersten
        Add-Gadgets ja 1-stellige oder dann 2-stellige Zahlen
        addieren müssen und erst die weniger obersten Gadgets
        Zahlen mit $\Theta(\log n)$ Bits als Input bekommen.

    |> Topic
        $O(\log n)$ Tiefe mit 2-for-3-Addierern.

    Die vorherige Konstruktion mit den Addierern war schon
    deutlich effizienter als unsere pyramidenartige
    $\theta^m_l$ -Konstruktion, allerdings wurde das Ziel,
    eine Tiefe von $O (\log n)$ zu erreichen, wieder
    verfehlt, wenn auch knapp. Die Idee, die eine Tiefe von
    $O (\log n)$ erreichen wird, ist ebenso einfach wie
    genial.

    |> Statement
        title=*Lemma (2-for-3 Adder)*
        Es gibt einen Schaltkreis mit $O(n)$ Gates, Tiefe 2
        und Fan-In 2, der als Input drei $n$-stellige
        Binärzahlen $x,y,z$ nimmt und zwei $n+1$-stellige
        Binärzahlen $u, v$ ausgibt, so dass

        $$
        x + y + z = u + v
        $$

        gilt.

    |> Highlight
        title=*Beweis.*
        Ich demonstriere das Beweisprinzip erst einmal mit
        drei Zahlen in Basis 10:

        |> figure
            |> img
                style=height:10em
                src=./img/circuits/2-for-3-adder-example.svg
                loading=lazy

        Wir addieren also pro Stelle drei (einstellige)
        Zahlen, führen den Übertrag (das Carry) aber nicht der
        weiter links stehenden Stelle zu, sondern sammeln alle
        Überträge und bilden daraus die $n+1$ -stellige Zahl
        $u$. Für Binärzahlen ist das natürlich noch einfacher:

        |> figure
            |> img
                style=height:15em
                src=./img/circuits/2-for-3-adder-binary.svg
                loading=lazy

        Dieser Schaltkreis hat insgesamt $O(n)$ Gates und
        Tiefe 2 (wobei wir die NOT-Gates im $\oplus$-Gate
        nicht mitzählen).
        |> QED

    Wir interpretieren nun die $n$ Inputs $x_1,\dots,x_n$
    von Majoroty als einstellige Binärzahlen, sortieren sie
    in Dreiergruppen und machen per 2-for-3-Addierer daraus
    $\ceil{\frac{2n}{3}}$ Zahlen. Dann machen wir (mit den
    mittlerweile 2-stelligen Zahlen) weiter und bekommen
    circa $\ceil{\frac{4n}{9}}$ Zahlen. Auf jeder Ebene
    schrumpft die Anzahl der Zahlen um einen Faktor von
    $\frac{2}{3}$; nach $\log_{3/2} n$ Ebenen haben wir
    schließlich noch zwei mittlerweile ($\log n$ )-stellige
    Zahlen, die wir mit einem "normalen" Binäraddierer
    addieren. Das Ergebnis vergleichen wir mit dem
    $\geq$-Schaltkreis mit $\frac{k+1}{2}$. Was ist die
    Tiefe des Gesamtschaltkreises? Es ist

    \begin{align*}
    &\log_{3/2} n \times \depth(\textnormal{2-for-3 adder}) \\
    +&
    \depth(\textnormal{Binäraddierer für ($\log n$)-stellige Zahlen}) \\
    +&
    \depth(\textnormal{$\geq$-Schaltkreis für ($\log n$)-stellige Zahlen} \\
    =&
    O(\log n) + O(\log \log n) + O(\log \log n) = O(\log n) \ .
    \end{align*}

    Die Größe des Schaltkreises wird dominiert von den
    2-for-3-Addierern. Wir haben $O(n)$ viele davon,
    allerdings hat jeder bis zu $O(\log n)$ viele Gates, da
    wir ja ($\log n$ )-stellige Zahlen addieren müssen; wir
    haben insgesamt also $O (n \log n)$ viele Gates.

    |> Statement
        title=*Theorem*
        Die Konstruktion mit 2-for-3-Addierern gibt uns einen
        Schaltkreis für Majority mit Fan-in 2, Tiefe
        $O(\log n)$ und Größe $O (n \log n)$

    |> Exercise
        Führen Sie eine genauere Abschätzung der Größe durch.
        Untersuchen Sie insbesondere:

        |> ol
            |> li
                Wieviele 2-for-3-Addierer haben Sie in Ebene $i$
                des Baumes?

            |> li
                Wieviel Bits haben die Zahlen auf Ebene $i$, und
                wie groß muss daher der 2-for-3-Addierer sein?

            |> li
                Was ergibt sich insgesamt in Summe?

    Wir haben nun also fast alle unserer Ziele erreicht.
    Allerdings hat die Konstruktion mit 2-for-3-Addierern
    einen Schönheitsfehler: sie ist nicht monoton. Warum
    sollten wir das wollen? Nun ja, Majority ist eine
    monotone Funktion, also ist es ja irgendwie verständlich,
    dass wir auch einen monotonen Schaltkreis wollen. Unser
    Pyramidenschema, in dem wir alle $\theta^m_k$ berechnen,
    ist monoton, hat allerdings leider Tiefe $\Omega(n)$.

    |> Topic
        Monoton und polylogarithmische Tiefe durch Halbierung
        und Aufzählung.

    Die Idee ist, dass wir, anstatt $\theta^n_k$ aus $x_n$ ,
    $\theta^{n-1}_{k-1}$ und $\theta^{n-1}_{k}$ zu
    berechnen, versuchen, irgendwie von $n$ auf $n/2$
    runterzukommen. Dann könnten wir rekursiv weitermachen
    und müssten uns nur durch logarithmisch viele Werte von
    $n$ wühlen. Wir sehen, dass wir $k$ auf $k+1$ Weisen als
    Summe zweier nichtnegativer Zahlen $a+b = k$ schreiben
    können. Des weiteren zerlegen wir
    $\mathbf{x} \in \{0,1\}^n$ in
    $\mathbf{y} = (x_1, \dots, x_{n/2})$ und
    $\mathbf{z} = (x_{n/2+1}, \dots, x_n)$ und sehen, dass

    \begin{align*}
    \sum_i x_i&\geq k \quad \Longleftrightarrow \\
    \sum_i y_i&\geq a \wedge \sum_j z_j \geq b
    \textnormal{ für Werte $a,b \geq 0$ mit $a + b = k$}
    \end{align*}

    und somit

    \begin{align*}
    \theta^n_k(\mathbf{x})&= \bigvee_{a=0}^k
    ( \theta^{n/2}_a (\mathbf{y}) \wedge
    \theta^{n/2}_{k-a} (\mathbf{z}) )
    \end{align*}

    Wenn wir diese Konstruktion rekursiv fortsetzen,
    erhalten wir $\log n$ Ebenen und somit auf den ersten
    Blick logarithmische Tiefe. Auf den zweiten Blick
    erkennen wir, dass wir etwas geschummelt haben: die
    $\bigvee$-Gates haben sehr großen Fan-in, nämlich bis zu
    $n$. Um Fan-in 2 zu erreichen, müssen wir jedes
    $\bigvee$-Gate durch einen Binärbaum aus normalen
    $\vee$-Gates von Fan-in 2 ersetzen. Dies gibt uns
    zusätzlich Tiefe $O(\log n)$ _pro $\bigvee$-Gate_; wir
    erhalten also insgesamt eine Tiefe von $O(\log^2 n)$.

    |> Exercise
        dass polynomiell viele (in diesem Falle: $O(n^2)$
        viele) Gates ausreichen. Zeigen Sie, wie die gerade
        skizzierte Konstruktion so ausgeführt werden kann,

    |> Topic
        Monoton und logarithmische Tiefe: Valiants
        probabilitische Konstruktion

    |> Statement
        title=*Theorem*
        Es gibt einen monotonen Schaltkreis mit Fan-in 2,
        Tiefe $O(\log n)$ und Größe $\poly(n)$, der $\maj_n$
        berechnet.

    |> Highlight
        title=*Beweis.*
        Die Beweismethode, die wir verwenden, ist womöglich
        neu für Sie. Wir verwenden bei der Konstruktion des
        Schaltkreises _Zufall_; am Ende werden wir zeigen, dass
        dieser zufällige Schaltkreis mit hoher
        Wahrscheinlichkeit $\maj_n$ auf allen möglichen $2^n$
        Inputs korrekt berechnen, und folgern daraus, das
        etwas, was mit hoher Wahrscheinlichkeit eintritt, auch
        existieren muss. Die Existenz folgt also schlussendlich
        aus einer Wahrscheinlichkeitsrechnung. Das heißt auch,
        dass ich Ihnen für konkretes $n$, sagen wir $n = 99$,
        nicht hinschreiben könnte, wie ein korrekter
        Schaltkreis aussähe; ich könnte die randomisierte
        Konstruktion durchführen und Ihnen erklären, das der
        resultierende Schaltkreis höchstwahrscheinlich korrekt
        ist. Während des ganzen Beweises müssen Sie sich vor
        Augen halten, dass wir bei der Konstruktion des
        Schaltkreises $C$ Zufall verwenden; wir nehmen nicht
        an, dass die Inputs $x \in \{0,1\}^n$ in irgendeiner
        Weise zufällig sind. Wir verwenden also
        _Wahrscheinlichkeitsverteilungen über Schaltkreisen_,
        nicht von über Inputs. Zuerst definieren wir die
        _Signalstärke_ von Verteilungen über Schaltkreise.

        |> Statement
            title=*Definition (Signalstärke)*
            Sei $\mathcal{C}$ eine Verteilung über Schaltkreise
            mit Input-Variablen $x_1,\dots,x_n$. Wir sagen, dass
            $\mathcal{C}$ _Signalstärke mindestens $\delta$_
            hat, wenn

            $$
            \forall x \in \{0,1\}: \quad \Pr_{C \in \mathcal{C}} [C(x) = \maj_n(x)]
            \geq \frac{1 + \delta}{2}
            $$

            gilt.

        In Worten, wenn der zufällig ausgewählte Schaltkreis
        $C$ den Wert $\maj_n(x)$ besser als ein Münzwurf
        vorhersagt, und zwar um $\delta/2$ besser. Wir können
        einen ganz einfachen (zufälligen Schaltkreis) bauen,
        der ein schwache aber positive Signalstärke hat.

        |> Statement
            title=*Lemma*
            Es gibt eine Wahrscheinlichkeitsverteilung
            $\mathcal{C}_0$ über monotone Schaltkreise der Größe
            1, die Signalstärke $\frac{1}{n}$ hat. Genauer
            gesagt gilt für jeden Input $x \in \{0,1\}^n$: ein
            nach dieser Verteilung zufällig ausgewählter
            Schaltkreis $C \sim \mathcal{C}_0$ ist mit
            Wahrscheinlichkeit mindestens
            $\frac{1}{2} + \frac{1}{2n}$ korrekt ist. Formal
            ausgedrückt:

            $$
            \forall \x \in \cube^n: \quad
            \Pr_{C \sim \mathcal{C}_0} [C(\x) = \maj_n(\x)] = \frac{1}{2} + \frac{1}{2n} \ .
            $$

        |> Remark
            title=*Beweis.*
            Der Schaltkreis bzw. die
            Wahrscheinlichkeitsverteilung ist extrem einfach. Wir
            wählen zufällig einen Index $I \in \{1,\dots,n\}$
            und geben $x_I$ als unseren Schaltkreis $C$
            (bestehend aus einem einzigen Input-Gate, das
            gleichzeitig das Output-Gate ist) aus. Dieser
            Schaltkreis ist natürlich monoton. Beachten Sie, dass
            ich den Index groß geschrieben mit $I$ bezeichne,
            nicht $i$; das ist Konvention, weil $I$ eine
            Zufallsvariable ist. Sei nun ein festes
            $\x \in \{0,1\}$ gegeben. Mit welcher
            Wahrscheinlichkeit ist unser (recht primitiver)
            Schaltkreis korrekt?

            \begin{align*}
            C(\x)&= \maj_n (\x) \quad \Longleftrightarrow \\
            x_I&= \maj_n (\x) \ .
            \end{align*}

            Wir unterscheiden nun zwei Fälle. Wenn
            $\maj_n(\x) = 1$ ist, dann gibt es mindestens $k+1$
            Indizes $i$ mit $x_i = 1$. Wenn wir mit $I$ einen
            solchen ausgewählt haben, dann sind wir erfolgreich.
            Die Wahrscheinlichkeit hierfür ist

            \begin{align*}
            \Pr_{C \sim \mathcal{C}_0} [C(\x) = 1] = \Pr_{I \in [n]} [x_I = 1]&= \frac{| \{i \in [n]\
            |
            x_i = 1\}}{n} \geq \frac{k+1}{n} \\
            &= \frac{k+1}{2k+1} = \frac{k + \frac{1}{2} + \frac{1}{2}}{2k+1} \\
            &= \frac{1}{2} + \frac{1}{2n} \ .
            \end{align*}

            Wenn nun $\maj_n(\x) = 0$ ist, dann gibt es
            mindestens $k+1$ Stellen $i$ mit $x_i = 0$, und
            somit ist $C(\x)$ auch wieder mit Wahrscheinlichkeit
            mindestens $\frac{k+1}{n+1}$ korrekt.
            |> QED

        Um eine Analogie aus dem Alltag zu bemühen: wenn Sie
        für eine Wahlprognose _einen_ zufällig ausgewählten
        Bürger befragen, so ist das Ergebnis zwar nicht
        wirklich repräsentativ, aber immerhin leicht besser,
        als wenn Sie einfach raten würden. Unser zufälliger
        Schaltkreis sendet uns also ein schwaches aber
        positives Signal in die richtige Richtung. Die
        Signalstärke ist $\frac{1}{n}$. Die zweite Zutat ist
        nun ein "Signalverstäker". Angenommen, eine Verteilung
        $\mathcal{C}$ hat Signalstärke $\delta$, also

        $$
        \forall \x \in \{0,1\}^n : \quad
        \Pr_{C \sim \mathcal{C}} [C(\x) = \maj_n(\x)] \geq \frac{1+\delta}{2} \ .
        $$

        Dann können wir _drei_ Schaltkreise
        $C_1, C_2, C_3 \sim \mathcal{C}$ unabhängig
        voneinander samplen und einen neuen Schaltkreis bauen:
        $C'(\x) := \maj_3 (C_1(\x), C_2(\x), C_3(\x))$. Dies
        gibt uns wiederum eine Verteilung über Schaltkreise,
        die wir $\mathcal{C}^{\otimes 3}$ nennen. Diese hat
        eine höhere Signalstärke:

        |> Statement
            title=*Lemma*
            Falls $\mathcal{C}$ eine Verteilung über
            Schaltkreise der Tiefe $d$ und Größe $s$ ist und
            $\mathcal{C}$ Signalstärke $\delta$ hat, dann gilt:

            |> ol
                |> li
                    alle Schaltkreise in $\mathcal{C}^{\otimes 3}$
                    haben Tiefe $d+2$;

                |> li
                    alle Schaltkreise in $\mathcal{C}^{\otimes 3}$
                    haben Größe $3s+4$;

                |> li
                    die Signalstärke von $\mathcal{C}^{\otimes 3}$
                    ist $\frac{3}{2} \delta - \frac{1}{2}\delta^3$ .

        |> Highlight
            title=*Beweis.*
            Wir betrachten ein festes $\x \in \cube^n$ mit
            $\maj_n(\x) = 1$; der Fall $\maj_n(\x) = 0$ ist
            analog. Wir definieren nun $U := C_1(\x)$,
            $V := C_2(\x)$ und $W := C_3(\x)$. Da
            $C_1, C_2, C_3 \sim \mathcal{C}$ zufällige
            Schaltkreise sind, sind $U, V, W$ Zufallsvariable
            über $\cube$, und zwar _unabhängig_, weil wir
            $C_1, C_2, C-3$ auch unabhängig gesampelt haben. Wir
            wissen:
            $\Pr[U=1] = \Pr[V=1] = \Pr[W=1] \geq
            \frac{1+\delta}{2} =: p$
            .
            Was ist nun $\Pr[\maj_3(U,V,W) = 1]$?

            \begin{align*}
            \Pr[\maj_3(U,V,W)=1]&= \Pr[U=V=W=1] + \Pr[\textnormal{genau zwei von $\{U,V,W\}$ sind 1}]
            \\
            &= p^3 + 3p^2 (1-p) = \pfrac{1 + \delta}{2}^3 + 3 \pfrac{1 + \delta}{2}^2 \frac{1 -
            \delta}{2} \\
            &= \frac{1}{8} (4 + 6 \delta - 2 \delta^3) \\
            &= \frac{1}{2} \left( 1 + \frac{3}{2} \delta - \frac{1}{2}\delta^3 \right) \ .
            \end{align*}

            Die Signalstärke von $\mathcal{C}^{\otimes 3}$ ist
            also mindestens
            $\frac{3}{2} \delta - \frac{1}{2} \delta^3$.
            |> QED

        Wir beginnen nun mit der Verteilung $\mathcal{C}_0$
        über Schaltkreise der Größe 1 und definieren

        \begin{align*}
        \mathcal{C}_{i+1} := (\mathcal{C}_i)^{\oplus 3} \ .
        \end{align*}

        Zur Wiederholung: um $C \sim \mathcal{C}_{i+1}$ zu
        sampeln, sampeln wir unabhängig drei Schaltkreise
        $\sim \mathcal{C}_i$ und verknüpfen deren Output-Gates
        mit einem $\maj_3$-Gadget. Wenn $\mathcal{C}_i$ die
        Signalstärke $\delta_i$ hat, dann hat
        $\mathcal{C}_{i+1}$ Signalstärke
        $\frac{3}{2} \delta_i - \frac{1}{2} \delta_i^3$. Wenn
        $\delta_i \leq 1/2$ sein sollte, dann ist das
        mindestens $\frac{5}{4} \delta_i$. Daraus folgt, dass
        nach höchstens $i^* := \log_{5/4} n$ Rekursionsstufen
        eine Signalstärke von mindestens $1/2$ erreicht ist:
        $\mathcal{C}_{i^*}$ hat Signalstärke mindestens $1/2$.
        Wenn wir jetzt die rekursive Konstruktion fortsetzen,
        steigt die Signalstärke weiter an und konvergiert gegen
        $1$:

        $\lim_{i \rightarrow \infty} \delta_i = 1$. Die Frage
        ist nur, wie schnell konvergiert es? Da wir nun nicht
        mehr an Wahrscheinlichkeiten interessiert sind, die
        knapp über $1/2$ liegen, sondern an solchen, die knapp
        unter $1$ liegen, führen wir einen Parameterwechsel
        durch: eine Verteilung $\mathcal{C}$ von Schaltkreisen
        mit Inputs $x_1,\dots,x_n$ hat
        _Fehlerwahrscheinlichkeit $\epsilon$_, wenn

        \begin{align*}
        \forall \x \in \cube^n: \Pr_{C \sim \mathcal{C}}[ C(\x) = \maj_n(\x)] \geq 1 - \epsilon \ .
        \end{align*}

        Eine Signalstärke von $\delta$ entspricht einer
        Fehlerwahrscheinlichkeit von $\frac{1-\delta}{2}$ .
        Die Verteilung $\mathcal{C}_{i^*}$ hat also eine
        Fehlerwahrscheinlichkeit von höchstens
        $\frac{1 - 1/2}{2} = 1/4$. Das obige Lemma, nun aus
        der Sicht der Fehlerwahrscheinlichkeit, liest sich so:

        |> Remark
            title=*Behauptung*
            Wenn $\mathcal{C}$ Fehlerwahrscheinlichkeit
            $\epsilon$ hat, dann hat $\mathcal{C}^{\otimes 3}$
            Fehlerwahrscheinlichkeit $3 \epsilon^2$

        |> Highlight
            title=*Beweis.*
            Wie im Beweis vom Lemma setzen wir
            $p := \frac{1+p}{2} = 1-\epsilon$ und erhalten

            \begin{align*}
            \Pr[\maj_3(U,V,W) = 1]&= p^3 + 3 p^2 (1-p) =
            (1 - \epsilon^3) + 3 (1- \epsilon)^2 \epsilon = 1 - 3 \epsilon^2 \ .
            \end{align*}

            Somit hat $\mathcal{C}^{\otimes 3}$
            Fehlerwahrscheinlichkeit $3 \epsilon^2$.
            |> QED

        Für $i^* := \log_{5/4} n$ hat $\mathcal{C}_{i^*}$ eine
        Fehlerwahrscheinlichkeit von höchstens $1/4$ . Für
        $i^* + 1$ wird das zu $3 \pfrac{1}{4}^2 = \frac{3}{16}$
        und für $i^* + 2$ zu
        $3 \pfrac{3}{16}^2 = \frac{27}{256} \leq
        \frac{1}{9}$ .
        Wenn nun $\epsilon \leq \frac{1}{9}$ ist, dann gilt
        $3 \epsilon^2 \leq \epsilon^{3/2}$. Wir definieren
        $\epsilon_i := \frac{1 - \delta_i}{2}$ , also die
        Fehlerwahrscheinlichkeit von $\mathcal{C}_i$. Es gilt
        also $\epsilon_{i+1} \leq (\epsilon_i)^{3/2}$ für alle
        $i \geq i^*+2$ und somit

        \begin{align*}
        \epsilon_{i^*+2 + j} \leq \left(\epsilon_{i^*}\right)^{\pfrac{3}{2}^j} \leq
        \pfrac{1}{4}^{\pfrac{3}{2}^j} \ .
        \end{align*}

        Qualitativ sehen wir: solange $\delta_i \leq 1/2$
        gilt, wächst die Signalstärke exponentiell an. Dieses
        exponentielle Wachstum kann natürlich nicht beliebig
        weitergehen. Jenseits $\delta_i \leq 1/2$ hört das
        auf, dafür _fällt_ nun die Fehlerwahrscheinlichkeit
        _doppelt exponentiell_. Für $j^* := \log_{3/2} n$ gilt
        dann

        \begin{align*}
        \epsilon_{i^* + 2 + j^*} \leq \pfrac{1}{4}^{n} \lt 2^{-n} \ .
        \end{align*}

        In Bildern:

        |> figure
            |> img
                style=height:18em
                src=./img/circuits/majority-probability-labeled.svg
            |> br
            Graph der Funktion $p \mapsto p^3 + 3 p^2 (1-p)$
        |> hr

        |> figure
            |> img
                style=height:18em
                src=./img/circuits/majority-probability-close-to-half-labeled.svg
            |> br
            Signalstärke $\delta$ wächst für $p \in [1/2, 3/4]$
            exponentiell.
        |> hr

        |> figure
            |> img
                style=height:18em
                src=./img/circuits/majority-probability-close-to-one-labeled.svg
            |> br
            Fehlerwahrscheinlichkeit $\epsilon$ fällt für
            $p \in [3/4, 1/2]$ doppelt exponentiell.
        |> hr
        Wir setzen nun
        $k := i^* + 2 + j^* = \log_{5/4} n + 2 + \log_{3/2}
        n = O(\log n)$
        und sehen, dass $\mathcal{C}_k$ eine Verteilung über
        Schaltkreise mit Tiefe $O(\log n)$ und
        Fehlerwahrscheinlichkeit kleiner als $2^{-n}$ ist. Was
        nun kommt, ist ein absolutes Standardargument in
        probabilitischen Beweisen: ein Union Bound. Das geht
        ungefähr so: wenn für jedes feste $\b \in \cube^n$ ein
        Schaltkreis $C \mathcal{C}_k$ mit Wahrscheinlichkeit
        $\epsilon_k$ irrt, dann ist die Wahrscheinlichkeit,
        dass $C$ sich für irgendein $\x \in \cube^n$ irrt,
        höchstens $2^n \epsilon_k$ . Formal: für jedes
        $\b \in \cube^n$ definieren wir $E_{\b}$ als die Menge
        der Schaltkreise mit Input-Variablen $x_1,\dots,x_n$,
        die sich auf $\b$ irren, also

        \begin{align*}
        E_{\b} := \{\textnormal{Schaltkreise } C \textnormal{ über } x_1, \dots, x_n \ | \ C(\b) \ne
        \maj_n(\b) \} \ .
        \end{align*}

        Die Verteilung $\mathcal{C}_k$ existiert ja im
        Wahrscheinlichkeitsraum aller Boolescher Schaltkreise
        mit Inputs $x_1,\dots, x_n$. Die Menge $E_{\b}$ ist
        somit ein _Ereignis_ in diesem Raum. Ein extrem
        unwahrscheinliches Ereignis:

        \begin{align*}
        \forall \b \in \cube^n: \Pr_{C \sim \mathcal{C}_k} [ C \in E_{\b} ] = \epsilon_k \lt 2^{n-} \ .
        \end{align*}

        Oder kompakt ausgedrückt:
        $\Pr_{\mathcal{C}_k} [E_{\b}] \lt 2^n$. Wir haben nun
        ein Ereignis $E_{\b}$ für jedes $\b \in \cube^n$ und
        definieren

        \begin{align*}
        E := \bigcup_{\b \in \cube^n} E_{\b} \ .
        \end{align*}

        Was ist $E$? Es ist die Menge der Schaltkreise, die
        sich auf mindestens einem $\b \in \cube^n$ irren. Was
        ist das Komplement $\bar{E}$? Das ist die Menge der
        Schaltkreise, die sich auf keinem $\b \in \cube^n$
        irren, also die Menge der Schaltkreise, die $\maj_n$
        korrekt berechnen. Es gilt nun

        \begin{align*}
        \Pr_{\mathcal{C}_k}[E]&= \Pr_{\mathcal{C}_k} \left[\bigcup_{\b \in \cube^n} E_{\b} \right] \\
        &\leq \sum_{\b \in \cube^n} \Pr_{\mathcal{C}_k} [E_{\b}] \\
        &= \sum_{b \in \cube^n} \epsilon_k\\
        &\lt \sum_{b \in \cube^n} 2^{-n} = 2^n 2^{-n} = 1 \ .
        \end{align*}

        Also $\Pr_{\mathcal{C}_k}[E] \lt 1$ und somit
        $\Pr_{\mathcal{C}_k}[\bar{E}] \gt 0$. Das bedeutet,
        dass ein zufälliger Schaltkreis $C \sim \mathcal{C}_K$
        mit positiver Wahrscheinlichkeit die Funktion $\maj_n$
        korrekt berechnet. Jeder Schaltkreis, der unter
        $\mathcal{C}_k$ gesampelt werden kann, hat Tiefe
        $O(\log n)$, Fan-in 2 und ist monoton, und somit
        schließen wir: es gibt einen monotonen Schaltkreis $C$
        mit Fan-in 2 und Tiefe $O(\log n)$, der $\maj_n$
        berechnet. Es bleibt die Frage, wie groß dieser
        Schaltkreis  $C$ ist. Seien wir hier bequem: ein
        Schaltkreis mit Fan-in 2 und einem Output-Gate hat
        höchstens $2^i$ Gates, die Abstand $i$ vom Output-Gate
        haben. Somit hat ein Schaltkreis mit Fan-in 2 und Tiefe
        $d$ höchstens

        \begin{align*}
        1 + 2 + 4 + \dots + 2^d = 2^{d+1}-1
        \end{align*}

        Gates. Ein Schaltkreis mit Fan-in 2 und Tiefe
        $c \log_2 n$ hat also insgesamt höchstens
        $2^{c \log n + 1 } - 1 = O(n^c) = O(\poly(n))$ Gates.
        |> QED

    |> Exercise
        Präzisieren Sie die Größe von Valiants Schaltkreis und
        bestimmen ein $c \in \R$, so dass er die Größe
        $\Theta(n^c)$ hat.

    Wir könnten nun noch ehrgeiziger sein und einen
    monotonen Schaltkreis mit Fan-in 2, Tiefe $O(\log n)$
    und _linearer_ Größe $O(n)$ anstreben.